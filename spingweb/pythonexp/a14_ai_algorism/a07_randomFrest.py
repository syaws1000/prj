'''
## 랜덤 포레스트: 여러 명의 탐정이 힘을 합쳐 정답을 찾는 방법

\*\*랜덤 포레스트(Random Forest)\*\*는 이름 그대로 '랜덤하게 만들어진 결정 트리(Decision Tree)들의 숲'입니다. 
여러 개의 결정 트리 모델을 만들어 각자의 예측을 종합하여 최종 결론을 내리는 **앙상블(Ensemble) 학습** 방법의 일종입니다. 
한 명의 탐정(결정 트리)에게만 의존하는 것보다, 여러 명의 탐정(결정 트리 숲)이 각자 다른 단서(데이터)를 가지고 추리한 뒤, 투표를 통해 결론을 내리는 것이 더 정확하고 안정적인 것과 같은 원리입니다.

-----

### 자세한 설명: 어떻게 동작하나요?

랜덤 포레스트는 크게 두 가지 핵심적인 '랜덤' 기법을 사용합니다.

1.  **데이터 샘플링의 무작위성 (배깅, Bagging)**

      * '**배깅(Bagging)**'은 **B**ootstrap **agg**regat**ing**의 약자입니다.
      * **부트스트랩 (Bootstrap)**: 원본 훈련 데이터에서 **중복을 허용하여** 여러 개의 작은 데이터 셋을 무작위로 만듭니다. 예를 들어 100개의 동물 데이터가 있다면, 1번 동물이 여러 번 뽑힐 수도 있고, 2번 동물은 한 번도 안 뽑힐 수도 있는 방식으로 100개의 데이터를 뽑아 하나의 작은 데이터 셋을 만듭니다. 이 과정을 여러 번 반복하여 여러 개의 데이터 셋을 생성합니다.
      * **통합 (Aggregating)**: 이렇게 만들어진 여러 개의 데이터 셋을 각각의 결정 트리(탐정)가 학습합니다. 그리고 새로운 문제를 예측할 때, 모든 트리의 예측 결과를 모아 **다수결 투표**를 통해 최종 결론을 내립니다. (예: 100개의 트리 중 90개가 '사자'라고 예측했다면 최종 답은 '사자'가 됩니다.)

2.  **특징 선택의 무작위성 (Feature Randomness)**

      * 각각의 트리가 데이터를 학습할 때, 전체 특징(질문)을 모두 고려하지 않습니다.
      * 예를 들어 '다리 개수', '날개 유무', '사는 곳', '크기' 등 10개의 특징이 있다면, 랜덤 포레스트는 각 트리(의 각 분기점)에서 이 중 일부 특징(예: 3개)만 무작위로 선택하여 최적의 질문을 찾게 합니다.
      * 이는 각 트리가 서로 다른 특징에 집중하게 만들어, 개성 있고 다양한 관점을 가진 트리(탐정)들을 만들어내는 효과를 줍니다. 특정 특징 하나에만 과도하게 의존하는 것을 방지하여 모델 전체의 안정성을 높입니다.

이 두 가지 무작위성 덕분에 랜덤 포레스트는 단일 결정 트리에 비해 **과적합(Overfitting, 훈련 데이터에만 너무 잘 맞아 실제 문제에서는 성능이 떨어지는 현상)에 훨씬 강하고, 전반적으로 더 높은 예측 정확도**를 보이는 강력한 모델이 됩니다.

-----

### 주요 핵심 코드 설명

제공해주신 결정 트리 코드를 랜덤 포레스트로 바꾸는 것은 매우 간단합니다. 탐정을 한 명에서 '탐정 팀'으로 바꾸는 것과 같습니다.

```python
# 1. 스무고개 탐정 '팀' 불러오기
# from sklearn.tree import DecisionTreeClassifier -> 이 부분을 바꿉니다.
from sklearn.ensemble import RandomForestClassifier

# 2. 스무고개 탐정 '팀'(랜덤 포레스트) 만들기
# detective = DecisionTreeClassifier() -> 이 부분을 바꿉니다.
# n_estimators는 숲을 구성할 나무(탐정)의 개수를 의미합니다.
detective_team = RandomForestClassifier(n_estimators=10, random_state=42)

# 3. 스무고개 문제로 탐정 '팀' 훈련시키기
# fit, predict 등 사용하는 방법은 완전히 동일합니다.
detective_team.fit(X_train, y_train)

# 4. 새로운 문제로 실력 테스트!
new_animal = [[1, 0, 0]]
prediction = detective_team.predict(new_animal)
```

  * `from sklearn.ensemble import RandomForestClassifier`

      * 단일 트리가 있는 `tree` 모듈 대신, 여러 모델을 합치는 `ensemble` 모듈에서 `RandomForestClassifier`(분류용 랜덤 포레스트)를 불러옵니다.

  * `RandomForestClassifier(n_estimators=10, random_state=42)`

      * 랜덤 포레스트 모델을 생성하는 부분입니다.
      * **`n_estimators=10`**: 이 파라미터가 핵심입니다. **숲을 구성할 결정 트리의 개수**, 즉 탐정 팀에 소속될 탐정의 수를 지정합니다. 일반적으로 이 숫자가 클수록 성능이 좋아지지만, 그만큼 계산 시간과 메모리 사용량이 늘어납니다.
      * **`random_state=42`**: 랜덤 포레스트는 내부적으로 데이터를 무작위로 샘플링합니다. `random_state` 값을 고정하면 코드를 다시 실행해도 항상 같은 방식의 무작위 샘플링을 하므로, 동일한 결과를 얻을 수 있습니다. (재현성을 위해 사용)

-----

### 코드에 대한 세부적인 설명

아래는 기존 코드를 랜덤 포레스트로 완전히 변경한 예시입니다.

```python
# 'sklearn'이라는 큰 도구 상자에서
# 여러 모델을 조합하는 'ensemble' 꾸러미 안에 있는
# 'RandomForestClassifier'(랜덤 포레스트 분류기)를 가져옵니다.
from sklearn.ensemble import RandomForestClassifier

# 1. 스무고개 문제와 정답 준비 (데이터는 동일)
# 특징: [다리가 4개?, 날개가 있나?, 물에 사나?]
X_train = [
    [1, 0, 0],  # 다리 4개, 날개 없음, 물에 안 삶 -> 사자
    [1, 1, 0],  # 다리 0개, 날개 있음, 물에 안 삶 -> 독수리
    [0, 0, 1],  # 다리 0개, 날개 없음, 물에 삶  -> 물고기
    [1, 0, 1],  # 다리 4개, 날개 없음, 물에 삶  -> 거북이
]
# 정답 (0: 사자, 1: 독수리, 2: 물고기, 3: 거북이)
y_train = [0, 1, 2, 3]


# 2. 스무고개 탐정 '팀'(랜덤 포레스트) 만들기
# 10명의 탐정(n_estimators=10)으로 구성된 팀을 만듭니다.
# random_state=42는 결과를 항상 동일하게 만들기 위한 설정입니다.
detective_team = RandomForestClassifier(n_estimators=10, random_state=42)


# 3. 스무고개 문제로 탐정 '팀' 훈련시키기
# detective_team의 탐정 10명이 각자 데이터를 나눠서 학습합니다.
# fit() 메서드 사용법은 DecisionTree와 완전히 동일합니다.
detective_team.fit(X_train, y_train)


# 4. 새로운 문제로 실력 테스트!
# 문제: 다리가 4개이고, 날개는 없고, 물에도 살지 않는 동물은 누구일까?
new_animal = [[1, 0, 0]]
# 10명의 탐정이 각자 추리한 뒤, 투표를 통해 최종 결론을 도출합니다.
prediction = detective_team.predict(new_animal)


# 5. 탐정 팀의 종합된 대답 확인하기
# 이 간단한 예제에서는 10명의 탐정 모두 '사자'라고 예측했을 가능성이 높습니다.
if prediction[0] == 0:
    print("스무고개 탐정 팀의 대답: '저희가 상의해 본 결과... 그 동물은 바로 사자군요!'")
elif prediction[0] == 1:
    print("스무고개 탐정 팀의 대답: '저희가 상의해 본 결과... 하늘을 나는 독수리군요!'")
elif prediction[0] == 2:
    print("스무고개 탐정 팀의 대답: '저희가 상의해 본 결과... 물에 있는 물고기군요!'")
elif prediction[0] == 3:
    print("스무고개 탐정 팀의 대답: '저희가 상의해 본 결과... 땅과 바다에 있는 거북이군요!'")

# 출력 결과:
# 스무고개 탐정 팀의 대답: '저희가 상의해 본 결과... 그 동물은 바로 사자군요!'
```



'''

from sklearn.tree import DecisionTreeClassifier

# 1. 스무고개 문제와 정답 준비
# [다리가 4개?, 날개가 있나?, 물에 사나?] -> 이런 특징을 'X'라고 부를게요.
X_train = [
    [1, 0, 0],  # 다리 4개, 날개 없음, 물에 안 삶 -> 사자
    [1, 1, 0],  # 다리 0개, 날개 있음, 물에 안 삶 -> 독수리
    [0, 0, 1],  # 다리 0개, 날개 없음, 물에 삶   -> 물고기
    [1, 0, 1],  # 다리 4개, 날개 없음, 물에 삶   -> 거북이
]
# 정답 (0: 사자, 1: 독수리, 2: 물고기, 3: 거북이) -> 이걸 'y'라고 불러요.
y_train = [0, 1, 2, 3]

# 2. 스무고개 탐정(결정 트리) 만들기
detective = DecisionTreeClassifier()

# 3. 스무고개 문제로 탐정 훈련시키기
detective.fit(X_train, y_train)

# 4. 새로운 문제로 실력 테스트!
# 문제: 다리가 4개이고, 날개는 없고, 물에도 살지 않는                           v 동물은 누구일까?
new_animal = [[1, 0, 0]]
prediction = detective.predict(new_animal)

# 5. 탐정의 대답 확인하기
if prediction[0] == 0:
    print("스무고개 탐정의 대답: '음... 그 동물은 바로 사자군요!'")
elif prediction[0] == 1:
    print("스무고개 탐정의 대답: '하늘을 나는 독수리군요!'")
elif prediction[0] == 2:
    print("스무고개 탐정의 대답: '물에 있는 물고기군요!'")
elif prediction[0] == 3:
    print("스무고개 탐정의 대답: '땅과 바다에 있는 거북이군요!'")

# ... (이하 생략)

# 출력 결과:
# 스무고개 탐정의 대답: '음... 그 동물은 바로 사자군요!'

