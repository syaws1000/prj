'''
CRM(Customer Relationship Management) ì‹œìŠ¤í…œì—ì„œ **Linear Regression(ì„ í˜• íšŒê·€)** ì„ í™œìš©í•˜ë©´, **ìˆ«ìë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ëª¨ë“  ì§€í‘œ**ì— ëŒ€í•´ ìœ ìš©í•˜ê²Œ ì“°ì…ë‹ˆë‹¤.

---

## âœ… CRMì—ì„œ Linear Regressionìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ í•­ëª©ë“¤

| ì˜ˆì¸¡ ëŒ€ìƒ                                          | ì„¤ëª…                                         |
| ---------------------------------------------- | ------------------------------------------ |
| ğŸ”¢ **ê³ ê° ìƒì•  ê°€ì¹˜ (CLV, Customer Lifetime Value)** | ê³ ê°ì´ ì•ìœ¼ë¡œ íšŒì‚¬ì— ê°€ì ¸ë‹¤ì¤„ **ì´ ìˆ˜ìµ ì˜ˆì¸¡**               |
| ğŸ’¸ **êµ¬ë§¤ ê¸ˆì•¡ (Purchase Amount)**                 | ê³ ê°ì˜ **ë‹¤ìŒ êµ¬ë§¤ ê¸ˆì•¡** ì˜ˆì¸¡                        |
| ğŸ• **ë‹¤ìŒ êµ¬ë§¤ ì‹œì  (Next Purchase Time)**           | ë©°ì¹  í›„ ë‹¤ì‹œ êµ¬ë§¤í• ì§€ ì˜ˆì¸¡ (ìˆ˜ì¹˜í˜•ì¼ ê²½ìš°)                  |
| ğŸ›ï¸ **ì¥ë°”êµ¬ë‹ˆ ì´ì•¡ (Cart Value)**                   | ì¥ë°”êµ¬ë‹ˆì— ë‹´ê¸´ ìƒí’ˆì˜ í‰ê·  êµ¬ë§¤ì•¡ ì˜ˆì¸¡                     |
| ğŸ“ **ê³ ê° ì„œë¹„ìŠ¤ ì†Œìš” ì‹œê°„**                            | ê³ ê° ì‘ëŒ€ì— ê±¸ë¦¬ëŠ” í‰ê·  ì‹œê°„ ì˜ˆì¸¡                        |
| ğŸ“§ **ìº í˜ì¸ ë°˜ì‘ë¥ **                                 | ìº í˜ì¸ì— ë”°ë¥¸ **ì‘ë‹µ ìˆ˜ì¹˜ ì˜ˆì¸¡ (ë¹„ìœ¨, ìˆ˜ëŸ‰)**              |
| ğŸ’¬ **ë¦¬ë·° ìˆ˜/í‰ì **                                 | íŠ¹ì • ìº í˜ì¸/ì œí’ˆ í›„ì— ê³ ê°ì´ ë‚¨ê¸¸ **ë¦¬ë·° ìˆ˜**ë‚˜ **í‰ê·  í‰ì ** ì˜ˆì¸¡ |
| ğŸ’³ **í• ì¸ìœ¨ì— ë”°ë¥¸ ë§¤ì¶œ ë³€í™”**                           | í• ì¸ìœ¨ì´ ë†’ì•„ì§ˆìˆ˜ë¡ ë§¤ì¶œì´ ì–¼ë§ˆë‚˜ ì¦ê°€í•˜ëŠ”ì§€ ì˜ˆì¸¡                |

---

## ğŸ¯ ì˜ˆì‹œ: ê³ ê° ìƒì•  ê°€ì¹˜(CLV) ì˜ˆì¸¡

### ğŸ“Œ íŠ¹ì§• ë°ì´í„° ì˜ˆì‹œ

```python
# ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³ ê° ì •ë³´ (ì˜ˆì‹œ)
| ê³ ê°_ID | ì´êµ¬ë§¤íšŸìˆ˜ | í‰ê· êµ¬ë§¤ì•¡ | í‰ê· êµ¬ë§¤ê°„ê²© | ìº í˜ì¸ì‘ë‹µìˆ˜ | CLV |
|--------|-------------|-------------|---------------|----------------|------|
| C001   |      5      |    20,000   |     30ì¼      |       2        |  90,000 |
| C002   |     10      |    15,000   |     14ì¼      |       3        | 135,000 |
```

### ğŸ“Œ íŒŒì´ì¬ ì½”ë“œ ì˜ˆì‹œ

```python
import pandas as pd
from sklearn.linear_model import LinearRegression

# ìƒ˜í”Œ ë°ì´í„°
data = pd.DataFrame({
    'êµ¬ë§¤íšŸìˆ˜': [5, 10, 8, 15, 3],
    'í‰ê· êµ¬ë§¤ì•¡': [20000, 15000, 18000, 12000, 25000],
    'êµ¬ë§¤ê°„ê²©': [30, 14, 20, 10, 40],
    'ìº í˜ì¸ì‘ë‹µ': [2, 3, 1, 5, 0],
    'CLV': [90000, 135000, 110000, 180000, 70000]
})

X = data[['êµ¬ë§¤íšŸìˆ˜', 'í‰ê· êµ¬ë§¤ì•¡', 'êµ¬ë§¤ê°„ê²©', 'ìº í˜ì¸ì‘ë‹µ']]
y = data['CLV']

# ëª¨ë¸ í•™ìŠµ
model = LinearRegression()
model.fit(X, y)

# ìƒˆë¡œìš´ ê³ ê° ì˜ˆì¸¡
new_customer = [[7, 17000, 25, 2]]
predicted_clv = model.predict(new_customer)
print("ì˜ˆìƒ CLV:", predicted_clv[0])
```

---

## ğŸ’¼ ì‹¤ë¬´ì—ì„œ ìœ ìš©í•œ ì´ìœ 

| íš¨ê³¼             | ì„¤ëª…                          |
| -------------- | --------------------------- |
| ğŸ¯ ë§ˆì¼€íŒ… íš¨ìœ¨ í–¥ìƒ   | êµ¬ë§¤ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê³ ê°ì—ê²Œë§Œ ë¦¬ì†ŒìŠ¤ ì§‘ì¤‘ ê°€ëŠ¥  |
| ğŸ’° ì˜ˆì‚° ìµœì í™”      | CLV ë†’ì€ ê³ ê°ì—ê²Œ ë” í° í˜œíƒ ì œê³µ ì„¤ê³„    |
| ğŸ§  ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • | ê°ì´ ì•„ë‹Œ ìˆ˜ì¹˜ ê¸°ë°˜ ê³ ê° ë¶„ì„ ê°€ëŠ¥        |
| ğŸ•’ íƒ€ì´ë° ìµœì í™”     | ì¬êµ¬ë§¤ ì‹œì  ì˜ˆì¸¡ìœ¼ë¡œ ë¦¬ë§ˆì¸ë“œ ë©”ì‹œì§€ íƒ€ì´ë° ì¡°ì ˆ |

---

## ğŸ¤– í•¨ê»˜ ì ìš©í•˜ë©´ ì¢‹ì€ ì•Œê³ ë¦¬ì¦˜

| ì•Œê³ ë¦¬ì¦˜        | ìš©ë„                       |
| ----------- | ------------------------ |
| **ë¡œì§€ìŠ¤í‹± íšŒê·€** | ì´íƒˆ ê°€ëŠ¥ì„± 0/1ë¡œ ë¶„ë¥˜           |
| **ëœë¤ í¬ë ˆìŠ¤íŠ¸** | ì¤‘ìš” ë³€ìˆ˜ íŒŒì•… ë° ì„±ëŠ¥ ê°œì„          |
| **K-í‰ê· **    | ë¹„ìŠ·í•œ êµ¬ë§¤íŒ¨í„´ êµ°ì§‘í™” í›„ ì„ í˜• íšŒê·€ë¡œ ì˜ˆì¸¡ |

---

ì›í•˜ì‹œë©´ CLV ì™¸ì—ë„ `í• ì¸ìœ¨ vs ë§¤ì¶œ`, `ë¦¬ë§ˆì¼€íŒ… í›„ êµ¬ë§¤ ë°˜ì‘`, `ì´ë²¤íŠ¸ë³„ ë§¤ì¶œ íš¨ê³¼` ë“±ì„ ì˜ˆì¸¡í•˜ëŠ” ì˜ˆì œë„ ì œê³µí•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”!
í•„ìš”í•œ ì‹œë‚˜ë¦¬ì˜¤ ë§ì”€ ì£¼ì„¸ìš” ğŸ˜Š




ë¬¼ë¡ ì…ë‹ˆë‹¤!
ì´ë²ˆì—” **Linear Regression (ì„ í˜• íšŒê·€)** ì•Œê³ ë¦¬ì¦˜ì„ **ì‰½ê³  ì •í™•í•˜ê²Œ ì´í•´**í•˜ê³ ,
**ì•”ê¸°ë²• + í•µì‹¬ íŒŒì´ì¬ ì½”ë“œ**ê¹Œì§€ í•¨ê»˜ ì •ë¦¬í•´ë“œë¦´ê²Œìš”.
ì´ˆë³´ìë„ ë”± ê¸°ì–µë  ìˆ˜ ìˆê²Œ ì„¤ëª…ë“œë¦´ê²Œìš”. ğŸ˜

---

## âœ… Linear Regression (ë¦¬ë‹ˆì–´ ë¦¬ê·¸ë˜ì…˜) ì´ë€?

### ğŸ“Œ 1. ê¸°ë³¸ ê°œë…

* ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ **ê°€ì¥ ì˜ ë§ëŠ” ì§ì„ ì„ ì°¾ëŠ” ê²ƒ!**
* `y = ax + b` (1ì°¨ í•¨ìˆ˜ í˜•íƒœ)ë¥¼ ì´ìš©í•´ **xë¡œ yë¥¼ ì˜ˆì¸¡**í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

> ğŸ” ì˜ˆì‹œ: í‚¤ë¡œ ëª¸ë¬´ê²Œë¥¼ ì˜ˆì¸¡í•˜ê±°ë‚˜, ê³µë¶€ ì‹œê°„ìœ¼ë¡œ ì‹œí—˜ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆì–´ìš”!

---

### ğŸ“Œ 2. ì•Œê³ ë¦¬ì¦˜ í•µì‹¬ ì›ë¦¬

| ë‹¨ê³„ | ì„¤ëª…                                                            |
| -- | ------------------------------------------------------------- |
| 1  | `y = ax + b` í˜•íƒœì˜ ì§ì„ ì„ ê°€ì •í•œë‹¤                                     |
| 2  | ì‹¤ì œ yê°’ê³¼ ì˜ˆì¸¡í•œ yê°’ì˜ ì°¨ì´(`ì˜¤ì°¨`)ë¥¼ ê³„ì‚°í•œë‹¤                                 |
| 3  | ì˜¤ì°¨ ì œê³±ì˜ í•©(SSE: Sum of Squared Errors)ì„ **ìµœì†Œí™”**í•˜ëŠ” `a`, `b`ë¥¼ ì°¾ëŠ”ë‹¤ |
| 4  | ì°¾ì€ `a`, `b`ë¡œ ì˜ˆì¸¡ì„ í•œë‹¤!                                          |

---

## ğŸ§  ì•”ê¸° í¬ì¸íŠ¸ (í•œ ì¤„ ìš”ì•½)

> â€œ**í•œ ì¤„ë¡œ ê·¸ì–´ì„œ ì°¨ì´ë¥¼ ì¤„ì—¬ë¼!**â€
> â†’ ë°ì´í„°ë¥¼ ëŒ€í‘œí•˜ëŠ” **ì§ì„ ì„ ê·¸ì–´ì„œ ì˜¤ì°¨(ì°¨ì´)ë¥¼ ìµœì†Œí™”**í•˜ëŠ” ê²Œ í•µì‹¬

---

## ğŸ§ª í•µì‹¬ íŒŒì´ì¬ ì½”ë“œ (sklearn ê¸°ë°˜)

```python
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import numpy as np

# 1. ì…ë ¥ ë°ì´í„°(x)ì™€ ì¶œë ¥ ë°ì´í„°(y) ì¤€ë¹„
x = np.array([[1], [2], [3], [4], [5]])  # 2ì°¨ì› ë°°ì—´
y = np.array([1.5, 3.0, 4.5, 6.0, 7.5])  # ì‹¤ì œ yê°’

# 2. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LinearRegression()
model.fit(x, y)

# 3. íšŒê·€ ê³„ìˆ˜ í™•ì¸
a = model.coef_[0]       # ê¸°ìš¸ê¸°
b = model.intercept_     # yì ˆí¸
print(f"ê¸°ìš¸ê¸° a: {a}, ì ˆí¸ b: {b}")

# 4. ì˜ˆì¸¡ ë° ì‹œê°í™”
y_pred = model.predict(x)
plt.scatter(x, y, color='blue', label='ì‹¤ì œ ë°ì´í„°')
plt.plot(x, y_pred, color='red', label='ì˜ˆì¸¡ ì„ ')
plt.legend()
plt.title("Linear Regression")
plt.show()
```

---

## ğŸ§  í•µì‹¬ ì½”ë“œ ì•”ê¸°ë²• (ë§ì¥ë‚œ + ìŠ¤í† ë¦¬í™”)

| ì½”ë“œ ì¤„                         | ê¸°ì–µ ë¬¸ì¥             |
| ---------------------------- | ----------------- |
| `model = LinearRegression()` | â€œì§ì„  ì „ë¬¸ê°€ ë¶ˆëŸ¬ì˜¤ê¸°â€     |
| `fit(x, y)`                  | â€œxë¡œ yë¥¼ ë°°ìš°ê²Œ í•˜ê¸°â€    |
| `model.predict(x)`           | â€œì§ì„  ì „ë¬¸ê°€ê°€ ì˜ˆì¸¡ ì‹œì‘!â€  |
| `coef_`, `intercept_`        | â€œaì™€ b ê°’ êº¼ë‚´ê¸°!â€     |
| `plt.plot()`                 | â€œë¹¨ê°„ ì„ ìœ¼ë¡œ ë¯¸ë˜ë¥¼ ë³´ì—¬ì¤˜!â€ |

---

## ğŸ¯ ì‹¤ìƒí™œ ë¹„ìœ 

> â€œì‹œí—˜ ê³µë¶€ ì‹œê°„ì„ xì¶•ì— ë‘ê³ , ì„±ì ì„ yì¶•ì— ë†“ì!â€
> â†’ ê³µë¶€ ë§ì´ í•˜ë©´ ì ìˆ˜ë„ ë†’ì•„ì ¸ì„œ ì ë“¤ì´ ì˜¬ë¼ê°€ê² ì£ ?
> â†’ ê·¸ëŸ¬ë©´ ê·¸ ì ë“¤ ì‚¬ì´ë¥¼ **ìµœëŒ€í•œ ê°€ê¹Œì´ ì§€ë‚˜ê°€ëŠ” ì§ì„ **ì„ ê·¸ë¦¬ëŠ” ê²Œ ì„ í˜• íšŒê·€ì˜ˆìš”!

---

## ğŸ§  ì•”ê¸° ê¿€íŒ ìš”ì•½

| ê°œë…         | ê¸°ì–µë²•                                      |
| ---------- | ---------------------------------------- |
| ì§ì„          | y = ax + b                               |
| í•™ìŠµ         | ì˜¤ì°¨(ì‹¤ì œê°’ - ì˜ˆì¸¡ê°’)ì˜ ì œê³±ì„ ìµœì†Œí™”                   |
| ëª©ì          | ë¯¸ë˜ yë¥¼ xë¡œ ì˜ˆì¸¡                              |
| sklearn í•¨ìˆ˜ | `LinearRegression().fit()` â†’ `predict()` |

---

## ğŸ” ì—°ìŠµ ë¯¸ì…˜ ì œì•ˆ

1. `x = np.array([[10], [20], [30], [40], [50]])`
   `y = np.array([100, 200, 300, 400, 500])` ë¡œ ë°”ê¿”ì„œ ì‹¤ìŠµ
2. ì˜ˆì¸¡ê°’ì„ ê·¸ë˜í”„ ë§ê³  `print()`ë¡œ ì§ì ‘ í™•ì¸í•´ë³´ê¸°
3. `x = np.arange(1, 11).reshape(-1,1)` ë¡œ ë°”ê¿”ì„œ ì‹¤í—˜í•˜ê¸°

---

ì›í•˜ì‹œë©´ ì•„ë˜ ë‚´ìš©ë„ ì¶”ê°€ ì„¤ëª… ë“œë¦´ ìˆ˜ ìˆì–´ìš”:

* ë‹¤í•­ íšŒê·€ (Polynomial Regression)
* ê²°ì •ê³„ìˆ˜(RÂ²)ë¡œ ì •í™•ë„ ì¸¡ì •
* ì†ì‹¤ í•¨ìˆ˜ (Loss Function) ê³„ì‚° ì›ë¦¬

í•„ìš”í•˜ì‹  ë°©í–¥ì„ ì•Œë ¤ì£¼ì„¸ìš”!


'''


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 1. ì˜ˆì œ ë°ì´í„° ìƒì„±
study_hours = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # ë…ë¦½ë³€ìˆ˜ X
scores = np.array([30, 50, 65, 70, 85])               # ì¢…ì†ë³€ìˆ˜ y

# 2. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LinearRegression()
model.fit(study_hours, scores)

# 3. ì˜ˆì¸¡ ë° ê²°ê³¼ í™•ì¸
predicted = model.predict(study_hours)
print(f"ê¸°ìš¸ê¸°(slope): {model.coef_[0]:.2f}")
print(f"ì ˆí¸(intercept): {model.intercept_:.2f}")

# 4. ì‹œê°í™”
plt.rc('font', family='Malgun Gothic') # í•œê¸€ í°íŠ¸ ì„¤ì •
plt.scatter(study_hours, scores, color='blue', label='ì‹¤ì œ ë°ì´í„°')
plt.plot(study_hours, predicted, color='red', label='íšŒê·€ì„ ')
plt.xlabel('ê³µë¶€ ì‹œê°„')
plt.ylabel('ì ìˆ˜')
plt.title('ê³µë¶€ ì‹œê°„ vs ì ìˆ˜ (ì„ í˜• íšŒê·€)')
plt.legend()
plt.show()
